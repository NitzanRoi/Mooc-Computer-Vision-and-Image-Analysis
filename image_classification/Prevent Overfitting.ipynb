{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 - Overfitting\n",
    "\n",
    "In this lab, you must modify the convolutional neural network you built in the previous lab to counteract overfitting.\n",
    "\n",
    "> **Hints**:\n",
    "> - To copy your code from the previous lab to this module folder, open your notebook in the **Mod02** folder and save a copy of it. Then move the copy to this folder.\n",
    "> - If you did not complete the previous lab, use the sample solution as a starting point.\n",
    "> - Add data augmentation as you load the training data - for example by rotating or flipping the images. See the [PyTorch](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image) or [Keras](https://keras.io/preprocessing/image/) documentation for help with this.\n",
    "> - Add at least one drop layer to your CNN. See the [PyTorch](https://pytorch.org/docs/stable/nn.html#dropout-layers) or [Keras](https://keras.io/layers/core/) documentation for help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount files:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os, os.path\n",
    "folder = 'Moocs/edx_Microsoft'\n",
    "os.chdir('/content/drive/My Drive/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup:\n",
    "!pip install https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
    "!pip install torchvision\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data: now with Data-Augmentation\n",
    "import os\n",
    "\n",
    "def make_class_list(train_folder):\n",
    "    return sorted(os.listdir(train_folder))\n",
    "\n",
    "def load_data(train_folder):\n",
    "    \n",
    "    # Load all of the images\n",
    "    transformation = transforms.Compose([\n",
    "        # Randomly augment the image data\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=train_folder,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    return transformation, full_dataset\n",
    "    \n",
    "def split_data(full_dataset):\n",
    "    # Split into training 70% and testing 30% datasets\n",
    "    train_ratio = 0.7\n",
    "        \n",
    "    train_size = int(train_ratio * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = \\\n",
    "        torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def define_loader(train_dataset, test_dataset):    \n",
    "    size_of_batch = 15\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=size_of_batch,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=size_of_batch,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def main1():\n",
    "    train_folder = \"./data/classification/training\"\n",
    "    class_list = make_class_list(train_folder)\n",
    "    transformation, full_dataset = load_data(train_folder)\n",
    "    train_dataset, test_dataset = split_data(full_dataset)\n",
    "    train_loader, test_loader = define_loader(train_dataset, test_dataset)\n",
    "    \n",
    "#     print(class_list)\n",
    "#     print(len(train_loader.dataset))\n",
    "    \n",
    "    return train_loader, test_loader, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the net:\n",
    "\n",
    "# debug function - prints tensor's shape\n",
    "def print_debug(num_of_print, x):\n",
    "    print(num_of_print, ':', x.shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # A drop layer deletes 30% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.3)\n",
    "\n",
    "        # Lenet variation\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # out_channels=6\n",
    "        self.bn2_1 = nn.BatchNorm2d(num_features=6)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # out_channels=16\n",
    "        self.bn2_2 = nn.BatchNorm2d(num_features=16)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2_3 = nn.BatchNorm2d(num_features=120)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 4 * 4 * 120, out_features=84)\n",
    "        self.bn1 = nn.BatchNorm1d(84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Lenet variation\n",
    "        x=self.pool1(x)\n",
    "        x=self.pool1(x)\n",
    "        \n",
    "        x=self.conv1(x)\n",
    "        x=torch.sigmoid(self.pool2(x))\n",
    "        x=self.bn2_1(x)\n",
    "\n",
    "        # Select some features to drop to prevent overfitting (only during training)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=torch.sigmoid(self.pool3(x))\n",
    "        x=self.bn2_2(x)\n",
    "\n",
    "        x=self.conv3(x)\n",
    "        x=self.bn2_3(x)\n",
    "        \n",
    "        x=x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "\n",
    "        # print_debug(1, x)\n",
    "        \n",
    "        x=self.bn1(F.relu(self.fc1(x)))\n",
    "        \n",
    "        x=self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "        \n",
    "def main2_lenet():\n",
    "    train_loader, test_loader, class_list = main1()\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if (torch.cuda.is_available()):\n",
    "        # if GPU available, use cuda\n",
    "        device = \"cuda\"\n",
    "    \n",
    "    # Create an instance of the model class and allocate it to the device\n",
    "    model = Net(num_classes=len(class_list)).to(device)\n",
    "#     print(model)\n",
    "    return model, device, train_loader, test_loader, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test:\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, loss_criteria):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "               \n",
    "def test(model, device, test_loader, loss_criteria):\n",
    "    # Switch the model to evaluation mode (without backpropagate)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                                        avg_loss, correct, len(test_loader.dataset),\n",
    "                                        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss\n",
    "\n",
    "def run_all(model, device, train_loader, test_loader):\n",
    "    # Track metrics in these arrays\n",
    "    epoch_nums = []\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "#     Use an \"Adam\" optimizer to adjust weights\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001) # one option\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01) # second option\n",
    "    # optimizer = optim.SGD(params=model.parameters(), lr=0.001, momentum=0.9, \n",
    "    #                       weight_decay=1e-6, nesterov=True) # third option\n",
    "\n",
    "    # Specify the loss criteria\n",
    "    loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train epochs\n",
    "    epochs = 25\n",
    "    print('Training on', device)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch, loss_criteria)\n",
    "        test_loss = test(model, device, test_loader, loss_criteria)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)\n",
    "    \n",
    "    return epoch_nums, training_loss, validation_loss  \n",
    "    \n",
    "def main3():\n",
    "    model, device, train_loader, test_loader, class_list = main2_lenet()\n",
    "    epoch_nums, training_loss, validation_loss = run_all(model, device, train_loader, test_loader)\n",
    "    print('finish training')\n",
    "    return epoch_nums, training_loss, validation_loss, model, test_loader, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view loss graph:\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# globals for other cells\n",
    "epoch_nums, training_loss, validation_loss, model, test_loader, class_list = main3()\n",
    "\n",
    "def plot_loss():\n",
    "    plt.plot(epoch_nums, training_loss)\n",
    "    plt.plot(epoch_nums, validation_loss)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix:\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix():\n",
    "    truelabels = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    print(\"Getting predictions from test set...\")\n",
    "    for data, target in test_loader:\n",
    "        for label in target.data.numpy():\n",
    "            truelabels.append(label)\n",
    "            \n",
    "        if (torch.cuda.is_available()):\n",
    "            # if GPU available, use cuda\n",
    "            for prediction in model(data.cuda()).cpu().data.numpy().argmax(1):\n",
    "                predictions.append(prediction)\n",
    "        else:\n",
    "            for prediction in model(data).data.numpy().argmax(1):\n",
    "                predictions.append(prediction)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(truelabels, predictions)\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_list))\n",
    "    plt.xticks(tick_marks, class_list, rotation=85)\n",
    "    plt.yticks(tick_marks, class_list)\n",
    "    plt.xlabel(\"Predicted Shape\")\n",
    "    plt.ylabel(\"True Shape\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and deploy:\n",
    "\n",
    "model_file = 'my-classifier.pt'\n",
    "torch.save(model.state_dict(), model_file)\n",
    "print(\"Model saved\")\n",
    "\n",
    "# Delete the existing model variable\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for classification:\n",
    "\n",
    "# Helper function to resize image\n",
    "def resize_image(src_img, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image\n",
    "\n",
    "    # rescale the image so the longest edge is the right size\n",
    "    src_img.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new image of the right shape\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the rescaled image onto the new background\n",
    "    new_image.paste(src_img, (int((size[0] - src_img.size[0]) / 2), int((size[1] - src_img.size[1]) / 2)))\n",
    "    \n",
    "    # return the resized image\n",
    "    return new_image\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image_array):\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # These are the classes our model can predict\n",
    "    class_names = class_list\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the imagees\n",
    "    image_tensor = torch.stack([transformation(image).float() for image in image_array])\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = image_tensor\n",
    "\n",
    "    # Predict the class of each input image\n",
    "    predictions = classifier(input_features)\n",
    "    \n",
    "    predicted_classes = []\n",
    "    # Convert the predictions to a numpy array \n",
    "    for prediction in predictions.data.numpy():\n",
    "        # The prediction for each image is the probability for each class, e.g. [0.8, 0.1, 0.2]\n",
    "        # So get the index of the highest probability\n",
    "        class_idx = np.argmax(prediction)\n",
    "        # And append the corresponding class name to the results\n",
    "        predicted_classes.append(class_names[class_idx])\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "print(\"Functions created - ready to use model for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification:\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_model():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    return model\n",
    "\n",
    "def plot_classes(predictions, image_arrays):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    # plot each image with its corresponding prediction\n",
    "    for idx in range(len(predictions)):\n",
    "        a=fig.add_subplot(1,len(predictions),idx+1)\n",
    "        imgplot = plt.imshow(image_arrays[idx])\n",
    "        a.set_title(predictions[idx])\n",
    "\n",
    "\n",
    "def classify(test_image_files, test_folder, size, background_color, model):\n",
    "    # Empty array on which to store the images\n",
    "    image_arrays = []\n",
    "    # Get the images and show the predicted classes\n",
    "    for file_idx in range(len(test_image_files)):\n",
    "        img = Image.open(os.path.join(test_folder, test_image_files[file_idx]))\n",
    "        \n",
    "        # resize the image so it matches the training set -\n",
    "        # it  must be the same size as the images on which the model was trained\n",
    "        resized_img = np.array(resize_image(img, size, background_color))\n",
    "                        \n",
    "        # Add the image to the array of images\n",
    "        image_arrays.append(resized_img)\n",
    "\n",
    "    # Get predictions from the array of image arrays\n",
    "    # Note that the model expects an array of 1 or more images - just like the batches on which it was trained\n",
    "    return predict_image(model, np.array(image_arrays)), image_arrays\n",
    "\n",
    "def main4():\n",
    "    model = get_model()\n",
    "\n",
    "    test_folder = './data/classification/test'\n",
    "    test_image_files = os.listdir(test_folder)\n",
    "    size = (128,128)\n",
    "    background_color=\"white\"\n",
    "\n",
    "    predictions, image_arrays = classify(test_image_files, test_folder, size, background_color, model)\n",
    "    plot_classes(predictions, image_arrays)\n",
    "\n",
    "main4()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "colab": {
   "name": "Lab 01 - Overfitting.ipynb",
   "provenance": [],
   "private_outputs": true,
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}